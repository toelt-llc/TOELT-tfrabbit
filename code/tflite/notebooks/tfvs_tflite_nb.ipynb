{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "saved_model1 = './model1_mnist/'\n",
    "saved_model2 = './model2_mnist/'\n",
    "\n",
    "# Currently only working when the model is saved & loaded using the keras api, rather than the tf.saved_model api\n",
    "saved_model2_keras = './model2_keras/'\n",
    "reloaded_model = tf.keras.models.load_model(saved_model2_keras)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-20 11:26:56.000124: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Using tf MNIST data set this time \n",
    "mnist = tf.keras.datasets.mnist\n",
    "fash = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images_norm = train_images.astype(np.float32) / 255.0\n",
    "test_images_norm = test_images.astype(np.float32) / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional retrain + optional given network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF normal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# tf inference\n",
    "pred = reloaded_model.predict(test_images)\n",
    "predictions = np.argmax(pred, axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-20 11:27:04.606348: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TFLite"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# tflite conv + inference \n",
    "\n",
    "inf_time = []\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images_norm).batch(1).take(1000):\n",
    "        yield [input_value]\n",
    "\n",
    "def conv_int8(model_path):\n",
    "    start_conv = time.time()\n",
    "    # TODO set option to read it from saved model or from existing model\n",
    "    # for now : uses keras (existing model)\n",
    "    # converter1 = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "    converter1 = tf.lite.TFLiteConverter.from_keras_model(model_path)\n",
    "    converter1.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter1.representative_dataset = representative_data_gen\n",
    "    converter1.inference_input_type = tf.uint8\n",
    "    converter1.inference_output_type = tf.uint8\n",
    "\n",
    "    quant_model = converter1.convert()\n",
    "    end_conv = time.time()\n",
    "    inf_time.append(end_conv-start_conv)\n",
    "\n",
    "    return(quant_model)\n",
    "\n",
    "\n",
    "def interpret(model, test_set):\n",
    "    #start_int = time.time()\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    input_type = interpreter.get_input_details()[0]['dtype']\n",
    "    # Quantization parameters : \n",
    "    input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "    # whole set, currently only supports test_set as an array\n",
    "    interpreter.resize_tensor_input(input_index=input_details[0]['index'], tensor_size=np.shape(test_set))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 8bit quantization approximation\n",
    "    test_images_q = test_set / input_scale + input_zero_point\n",
    "    test_images_q = np.reshape(test_images_q.astype(input_type), np.shape(test_set)) # wordy line\n",
    "\n",
    "    # Loading into the tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_images_q)\n",
    "    end_int = time.time()\n",
    "\n",
    "    #inf_time.append(end_int-start_int)\n",
    "    return interpreter\n",
    "\n",
    "def run_inference(interpreter):\n",
    "    output_details = interpreter.get_output_details()\n",
    "    start_inf = time.time()\n",
    "    interpreter.invoke()\n",
    "    end_inf = time.time()\n",
    "    inference = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions = np.argmax(inference, axis=1)\n",
    "\n",
    "    inf_time.append(end_inf-start_inf)\n",
    "    print('Quantized model accuracy : ', (predictions == test_labels).mean())\n",
    "\n",
    "    return predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "quanted_model = conv_int8(reloaded_model)\n",
    "interpreter = interpret(quanted_model, test_images_norm)\n",
    "run_inference(interpreter)\n",
    "\n",
    "#print('Original model accuracy : {}'.format(round(eval[1],2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pj/_64wh_0d44z5f2y6mk2zml0w0000gn/T/tmpt5o0hec8/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/pj/_64wh_0d44z5f2y6mk2zml0w0000gn/T/tmpt5o0hec8/assets\n",
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Quantized model accuracy :  0.9795\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "inf_time\n",
    "print('Conversion time : {}, Inference time {}'.format(round(inf_time[0],2), round(inf_time[1],2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversion time : 0.96, Inference time 3.91\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "x_train.dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}