{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quantization on MNIST data set, 2d attempt "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Working as expected "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Using tf MNIST data set this time \n",
    "mnist = tf.keras.datasets.mnist\n",
    "fash = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2nd Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "model2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=5,\n",
    "  validation_data=(test_images, test_labels)\n",
    ")\n",
    "eval = model2.evaluate(test_images, test_labels)\n",
    "print(\"test loss, test acc:\", eval)\n",
    "tf.saved_model.save(model2, './model2_mnist/')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4902 - accuracy: 0.8305 - val_loss: 0.3908 - val_accuracy: 0.8618\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3575 - accuracy: 0.8758 - val_loss: 0.3548 - val_accuracy: 0.8771\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3246 - accuracy: 0.8859 - val_loss: 0.3370 - val_accuracy: 0.8812\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2998 - accuracy: 0.8955 - val_loss: 0.3151 - val_accuracy: 0.8886\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2828 - accuracy: 0.9003 - val_loss: 0.3034 - val_accuracy: 0.8913\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3034 - accuracy: 0.8913\n",
      "[0.3034186363220215, 0.8913000226020813]\n",
      "INFO:tensorflow:Assets written to: ./model2_mnist/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: ./model2_mnist/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Quantization blueprint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "path = './model1_mnist/'\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "# Conversion set-up \n",
    "\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "model = converter.convert()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### No quantization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Converted model interpreter \n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print('Input details : ', input_details)\n",
    "print('Output details :', output_details)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input details :  [{'name': 'serving_default_flatten_input:0', 'index': 0, 'shape': array([  1, 784], dtype=int32), 'shape_signature': array([ -1, 784], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details : [{'name': 'StatefulPartitionedCall:0', 'index': 12, 'shape': array([ 1, 10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since the input shape is set to 1,784 ( from the original TF model) we resize the input tensor before allocating it again.   \n",
    "Then we can load the whole test set to produce a production result that we can interpret thanks to argmax."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "test_images = test_images.reshape(10000,784)\n",
    "interpreter.resize_tensor_input(input_index = input_details[0]['index'],tensor_size=(10000,784))\n",
    "interpreter.allocate_tensors()\n",
    "interpreter.set_tensor(input_details[0]['index'], test_images)\n",
    "\n",
    "interpreter.invoke()\n",
    "tflite_predictions = interpreter.get_tensor(output_details[0]['index'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we get 98% prediction, which would be the precision o the noraml model, but no quantization was actually done : the datatype is till float32"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "pred = np.argmax(tflite_predictions, axis=1)\n",
    "print('Accuracy : ', (pred == test_labels).mean() )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy :  0.0707\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Post-training integer quantization\n",
    "\n",
    "Now we will reproduce the steps, but with the addition of the quantization steps"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(1000):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(path)\n",
    "\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8#,  \n",
    "    # tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    # tf.lite.OpsSet.SELECT_TF_OPS  \n",
    "]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "quant_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quant_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "input:  <class 'numpy.uint8'>\n",
      "output:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# To replace in the interpreter.set_tensor line for single inference : \n",
    "\n",
    "# test_images[10] = np.expand_dims(test_images[10], axis=0).astype(input_type)\n",
    "# test_images[10] = test_images[10] / input_scale + input_zero_point\n",
    "# dici = test_images[10].astype(input_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# Interpreter\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "#whole set \n",
    "interpreter.resize_tensor_input(input_index = input_details[0]['index'],tensor_size=(10000,784))\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_images_q = test_images / input_scale + input_zero_point\n",
    "test_images_q = np.reshape(test_images_q.astype(input_type), (10000,784))\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_images_q)\n",
    "\n",
    "# Invoke\n",
    "interpreter.invoke()\n",
    "tflite_predictions2 = interpreter.get_tensor(output_details[0]['index'])\n",
    "#tflite_predictions2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "pred2 = np.argmax(tflite_predictions2, axis=1)\n",
    "print('Accuracy : ', (pred2 == test_labels).mean())\n",
    "print('Predictions similarity noquant vs. quant : ', (pred2 == pred).mean())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy :  0.07\n",
      "Predictions similarity noquant vs. quant :  0.9926\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# #plt.imshow(np.reshape(test_images_int8[97], (28,28)))\n",
    "# plt.show()\n",
    "# plt.imshow(np.reshape(test_images[10], (28,28)))\n",
    "# type(test_images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Automatization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "fash = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fash.load_data()\n",
    "\n",
    "# Very important step\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model \n",
    "Here I can load any presaved model or train a new one"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Careful on what dataset model2 (and 1) is trained\n",
    "saved_model1 = './model1_mnist/'\n",
    "saved_model2 = './model2_mnist/'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(1000):\n",
    "        yield [input_value]\n",
    "\n",
    "def conv(model_path):\n",
    "    # TODO set option to read it from saved model or from existing model\n",
    "    converter1 = tf.lite.TFLiteConverter.from_saved_model(model_path)\n",
    "    converter1.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter1.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter1.representative_dataset = representative_data_gen\n",
    "    converter1.inference_input_type = tf.uint8\n",
    "    converter1.inference_output_type = tf.uint8\n",
    "\n",
    "    quant_model = converter1.convert()\n",
    "    return(quant_model)\n",
    "\n",
    "\n",
    "def interpret(model, test_set):\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    input_type = interpreter.get_input_details()[0]['dtype']\n",
    "    # Quantization parameters : \n",
    "    input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
    "\n",
    "    # whole set, currently only supports test_set as an array\n",
    "    interpreter.resize_tensor_input(input_index=input_details[0]['index'], tensor_size=np.shape(test_set))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # 8bit quantization approximation\n",
    "    test_images_q = test_set / input_scale + input_zero_point\n",
    "    test_images_q = np.reshape(test_images_q.astype(input_type), np.shape(test_set)) # too complex\n",
    "\n",
    "    # Loading into the tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_images_q)\n",
    "\n",
    "    return interpreter\n",
    "\n",
    "def run_inference(interpreter):\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.invoke()\n",
    "    inference = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predictions = np.argmax(inference, axis=1)\n",
    "    print('Accuracy : ', (predictions == test_labels).mean())\n",
    "\n",
    "    return predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Execution "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# possible TODO : make it only in a single function, with (saved_model, test_images) params\n",
    "quanted_model = conv(saved_model2)\n",
    "interpreter = interpret(quanted_model, test_images)\n",
    "run_inference(interpreter)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy :  0.8923\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With model2 :\n",
    "on mnist   : accuracy 0.98\n",
    "on fashion : accuracy 0.89"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}