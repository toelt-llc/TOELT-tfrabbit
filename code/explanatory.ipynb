{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Benchmarking Project"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## .1 First part : attempts at converting Tensorflow models to Tensorflowlite \n",
    "\n",
    "#### mnist_rpi \n",
    "Despite its name, this script was used to compare the different times between different devices.  \n",
    "These scripts take network parameters as arguments : neurons, layers, dataset (mnist|fashion), epoch, batch_size, test_set size.  \n",
    "Functions : - `load_data` - `run_model` - `run_tflite`  \n",
    "Used only a FNN, but modulable for CNNs. The interesting part is the ability to loop over lists of parameters (neurons and layers), to observe the different training (mostly) and inference time (minor differences).  \n",
    "The main result of this part : the first proper implementation of the tflite library, with an effective comparison of training/conversion time.  \n",
    "\n",
    "#### bash scripts \n",
    "These were used to run several times the mnist_rpi, to gain insight and confidence on the results.    \n",
    "Results are in `saved_results`, with subdirectories dedicated to each device the script was looped on (rpi|mac|GPUs).  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## .2 Second part : exploration of quantization using tflite, tf vs tflite comparison \n",
    "#### ./tflite/\n",
    "-Notebooks   \n",
    "`example` runs a TFLite example from the site, not really optimized for what we want to do here  \n",
    "`model_maker` is an example run of how to build and create a TFLite inference with the 'maker' library  \n",
    "`tflite_exploration` also uses model_maker, with an image classifier example and some tests  \n",
    "`tflite_converter` is the main notebook used for learning the library, it creates a TF model (saves it and reloads it) to then convert it to TFLite.  \n",
    "The TFLite invoker is then used with some mnist_data. So far the notebook succesfully translates and uses a TFLite interpreter.  \n",
    "NOTEBOOK DIR  \n",
    "\n",
    "-Scripts  \n",
    "`train_convert` specific for each dataset tested. Trains and save classic TF models (both a FNN and a CNN),   \n",
    "then convert both to .tflite format, using 4 different tflite setup (raw, quant, quantf16, quanti8). All these 4 versions are then saved.  \n",
    "Classic models are saved in <dataset_name>_model/ and lite models are saved in <dataset_name>_tflite_models/  \n",
    "`run_model_loop` also dataset dependant. Runs ALL the datasets (classics and lites) to compare the inference times.   \n",
    "Does it over a #loop(chosen) number of time, to compute a mean and a std.  \n",
    "\n",
    "-Results  \n",
    "<.csv> and <.pkl> contain the dataframe with the results of the loops of training. Models used for inference measurement is specified.  \n",
    "The number of loops and the device on which it was ran is specified in the file name.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}